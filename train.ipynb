{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import autopep8\n","import isort\n","from yapf.yapflib.yapf_api import FormatCode\n","\n","\n","# @register_cell_magic\n","def fmt(line, cell):\n","   \"\"\"\n","   My formatter cell magic comannd.\n","   Please install autopep8, isort and yapf before using this magic command.\n","   !pip install autopep8 isort yapf\n","   \"\"\"\n","   ret = isort.code(cell)\n","   ret = autopep8.fix_code(ret)\n","   print(FormatCode(ret, style_config='pep8')[0])\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Import\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import copy\n","import glob\n","import os\n","import random\n","\n","import albumentations as A\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torchvision as tv\n","from albumentations.pytorch import ToTensorV2\n","from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n","from sklearn.model_selection import train_test_split\n","from torch.optim import lr_scheduler\n","\n","from pytorchtools import EarlyStopping"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["random_seed = 3141\n","\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","if torch.cuda.device_count() > 1:\n","    torch.cuda.manual_seed_all(random_seed) # for multiple GPU\n","else:\n","    torch.cuda.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" # 1.Confirm dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["contact 3598\n","no_contact 5241\n","Total 8839\n"]}],"source":["img_paths = []  # Image path\n","class_ids = []  # Class ID according to the image path\n","class_names = []  # Class name\n","\n","target = \"mix\" #Target includes ham, chicken, mix\n","\n","img_dirs = sorted(glob.glob('C:/Users/eugene/Desktop/research_eugene/annotation/rename/' + target + '/train/**'))\n","val_dirs = sorted(glob.glob('C:/Users/eugene/Desktop/research_eugene/annotation/rename/' + target + '/val/**'))\n","test_dirs = sorted(glob.glob('C:/Users/eugene/Desktop/research_eugene/annotation/rename/' + target + '/test/**'))\n","\n","\n","for class_id, img_dir in enumerate(img_dirs):\n","\n","    class_names.append(img_dir.split(os.sep)[-1])\n","\n","    tmp_img_paths = sorted(glob.glob(f'{img_dir}/*'))\n","    print(class_names[-1], len(tmp_img_paths))\n","    for img_path in tmp_img_paths:\n","        img_paths.append(img_path)\n","        class_ids.append(class_id)\n","\n","print('Total', len(img_paths))\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" # 2.Transform"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from torchvision.transforms import ToTensor, CenterCrop, Compose\n","\n","train_transform = Compose([\n","    ToTensor(), \n","    CenterCrop([360, 360]),\n","\n","])\n","\n","\n","val_transform = Compose([\n","    ToTensor(), \n","    CenterCrop([360, 360]),\n","    \n","])\n","\n","\n","test_transform = Compose([\n","    ToTensor(), \n","    CenterCrop([360, 360]),\n","    \n","])\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","\n","\n","\n","img_dirs = 'C:/Users/eugene/Desktop/research_eugene/annotation/rename/' + target + '/train/'\n","val_dirs = 'C:/Users/eugene/Desktop/research_eugene/annotation/rename/' + target + '/val/'\n","test_dirs = 'C:/Users/eugene/Desktop/research_eugene/annotation/rename/' + target + '/test/'\n","\n","\n","train_dataset = ImageFolder(\n","    root=img_dirs,\n","    transform=train_transform\n",")\n","\n","val_dataset = ImageFolder(\n","    root=val_dirs,\n","    transform=val_transform\n",")\n","\n","\n","test_dataset = ImageFolder(\n","    root=test_dirs,\n","    transform=val_transform\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" # 3.CNN model"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def def_model():\n","    \"\"\"CNNモデルを定義し返す関数\n","\n","    Returns\n","    -------\n","    model : torchvision.models\n","        CNNモデル\n","    \"\"\"\n","\n","    # for efficientnet_b0\n","    # model = tv.models.efficientnet_b0(pretrained=True)\n","    # model.classifier._modules['1'] = torch.nn.Linear(1280, 2) \n","\n","\n","    # for efficientnet_b4\n","    model = tv.models.efficientnet_b4(pretrained=False) \n","    model.classifier._modules['1'] = torch.nn.Linear(1792, 2) \n","\n","    \n","\n","    if torch.cuda.is_available():\n","        model = model.cuda()\n","    return model\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" # 4.Train model & Test model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["early_stopping = EarlyStopping(patience=10, verbose=True, delta=0.005)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import torchvision\n","from torchvision import utils as vutils\n"," \n"," \n","def save_image_tensor(input_tensor: torch.Tensor, filename):\n","    \"\"\"\n","    save tensor as image\n","    :param input_tensor: the tensor to be saved\n","    :param filename: name to be saved\n","    \"\"\"\n","    assert (len(input_tensor.shape) == 4 and input_tensor.shape[0] == 1)\n","    # copy\n","    input_tensor = input_tensor.clone().detach()\n","    # to cpu\n","    input_tensor = input_tensor.to(torch.device('cpu'))\n","    vutils.save_image(input_tensor, filename)\n","\n","def train_model(model, loader, criterion, optimizer, pla_lr_scheduler):\n","    model.train()\n","    train_loss = 0.0\n","    for data in loader:\n","        inputs, labels = data\n","\n","        if torch.cuda.is_available():\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        outputs = torch.nn.functional.softmax(outputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    valid_loss = (train_loss / len(loader))      \n","    pla_lr_scheduler.step(valid_loss)\n","\n","    print(f\"Training loss: {train_loss / len(loader):.6f}\")\n","   \n","    return model\n","\n","\n","def test_model(model, loader, criterion):\n","    model.eval()\n","    test_loss = 0.0\n","    all_labels = []\n","    all_predicted = []\n","    error_path = 'C:/Users/eugene/Desktop/research_eugene/error_img/'\n","\n","    with torch.no_grad():\n","        for data in loader:\n","            inputs, labels = data\n","\n","            all_labels.append(labels.numpy())\n","\n","            if torch.cuda.is_available():\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","\n","            # model prediction\n","            outputs = model(inputs)\n","            outputs = torch.nn.functional.softmax(outputs)\n","            test_loss += criterion(outputs, labels)\n","            _, predicted = torch.max(outputs.data, 1) \n","            if torch.cuda.is_available():\n","                predicted = predicted.cpu()\n","            all_predicted.append(predicted.numpy())\n","\n","    # Evaluation\n","    labels = all_labels[0]\n","    predicted = all_predicted[0]\n","    for idx in range(1, len(all_labels)):\n","        labels = np.hstack((labels, all_labels[idx]))\n","        predicted = np.hstack((predicted, all_predicted[idx]))\n","\n","    accuracy = accuracy_score(labels, predicted)\n","    f1 = f1_score(labels, predicted, average='macro')\n","    cm = confusion_matrix(labels, predicted)\n","\n","    # early_stopping needs the validation loss to check if it has decresed, \n","    # and if it has, it will make a checkpoint of the current model\n","    early_stopping(test_loss/len(loader), model)\n","    \n","    \n","    print(\n","        f\"Accuracy: {accuracy:.3f}, F1: {f1:.3f}, Loss: {test_loss/len(loader):.6f}\"\n","    )\n","    print(\"Confusion matrix\")\n","    print(cm)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" # 5.Learning\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 200\n","batch_size = 16\n","lr = 1e-3\n","\n","\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","val_loader = torch.utils.data.DataLoader(val_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=False)\n","\n","\n","model = def_model().cuda()\n","criterion = torch.nn.CrossEntropyLoss().cuda() \n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","pla_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3, verbose=True)\n","\n","\n","for epoch in range(num_epochs):\n","\n","\n","    print(f\"Epoch: {epoch+1}\")\n","    model = train_model(model, train_loader, criterion, optimizer, pla_lr_scheduler = pla_lr_scheduler)\n","    test_model(model, val_loader, criterion)\n","    torch.save(model.state_dict(), 'C:/Users/eugene/Desktop/research_eugene/model/model' + str(epoch+1) +'.pth')\n","    \n","  \n","\n","    \n","    if early_stopping.early_stop:\n","        print(\"Early stopping\")\n","        break\n","\n","    \n","print(\"Training finished\")\n","\n","test_model(model, test_loader, criterion)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.6.13 ('research')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"818954601718e108c005db72636af7cf7d199bcabd998298ab389c861a9f9297"}}},"nbformat":4,"nbformat_minor":2}
